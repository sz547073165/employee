{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并训练集和待遇测集，统一处理。合并前多添加一列‘source’，分别用0和1，区分训练集和测试集。经检查，列‘Age’都是18岁以上，所以列‘Over18’无意义删除之，然后对个别的数据类型为str的列进行编码，处理完毕后拆分训练集和待遇测集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读取数据，合并统一处理\n",
    "df_train = pd.read_csv('pfm_train.csv')\n",
    "df_target = pd.read_csv('pfm_test.csv')\n",
    "df_train['source'] = 0\n",
    "df_target['source'] = 1\n",
    "X = pd.concat([df_train.drop('Attrition', axis=1),df_target],ignore_index=True)\n",
    "\n",
    "#清洗数据\n",
    "#print('under18 =',X[X['Age']<18].shape[0] == 0)\n",
    "X = X.drop(['Over18'],axis=1)\n",
    "column_list = ['BusinessTravel','Department','EducationField','Gender','JobRole','MaritalStatus','OverTime']\n",
    "X_le = pd.get_dummies(X[column_list])\n",
    "X = pd.merge(X,X_le,how='outer',left_index=True,right_index=True).drop(column_list,axis=1)\n",
    "\n",
    "#拆分数据\n",
    "X_train = X[X['source']==0].drop(['source'],axis=1)\n",
    "y_train = df_train['Attrition']\n",
    "X_target = X[X['source']==1].drop(['source'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier默认参数，训练后预测X_target，得分0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.824545454545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangmin/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/zhangmin/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "rfc_1 = RandomForestClassifier(oob_score=True, random_state=10)\n",
    "rfc_1.fit(X_train, y_train)\n",
    "print(rfc_1.oob_score_)\n",
    "result_1 = pd.DataFrame(rfc_1.predict(X_target),columns=['result'])\n",
    "result_1.to_csv('result_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数调整，首先对‘n_estimators’进行搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 140} 0.801725255323\n",
      "{'n_estimators': 136} 0.803001174664\n",
      "CPU times: user 863 ms, sys: 103 ms, total: 966 ms\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def search_1(param_list):\n",
    "    gs = GridSearchCV(estimator=RandomForestClassifier(random_state=10),param_grid=param_list_1,scoring='roc_auc',cv=5,n_jobs=-1)\n",
    "    gs.fit(X_train,y_train)\n",
    "    print(gs.best_params_,gs.best_score_)\n",
    "    return gs.best_params_['n_estimators']\n",
    "\n",
    "param_list_1 = {'n_estimators':np.arange(10,201,10)}\n",
    "best_n_estimators = search_1(param_list_1)\n",
    "param_list_1 = {'n_estimators':np.arange(best_n_estimators-10,best_n_estimators+10)}\n",
    "best_n_estimators = search_1(param_list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数调整，首先对‘max_depth’，‘min_samples_split’，‘min_samples_leaf’进行搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 21, 'min_samples_leaf': 1, 'min_samples_split': 22} 0.807887794344\n",
      "{'max_depth': 11, 'min_samples_leaf': 1, 'min_samples_split': 17} 0.809948683155\n",
      "{'max_depth': 13, 'min_samples_leaf': 1, 'min_samples_split': 10} 0.813730513546\n",
      "{'max_depth': 13, 'min_samples_leaf': 1, 'min_samples_split': 10} 0.813730513546\n",
      "CPU times: user 11.6 s, sys: 919 ms, total: 12.5 s\n",
      "Wall time: 4min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def search_2(param_list):\n",
    "    gs = GridSearchCV(estimator=RandomForestClassifier(n_estimators=best_n_estimators,random_state=10),\n",
    "                     param_grid=param_list,scoring='roc_auc',cv=5,n_jobs=-1)\n",
    "    gs.fit(X_train,y_train)\n",
    "    print(gs.best_params_,gs.best_score_)\n",
    "    return gs.best_params_['max_depth'], gs.best_params_['min_samples_split'], gs.best_params_['min_samples_leaf']\n",
    "\n",
    "param_list_2 = {'max_depth':np.arange(1,61,10),'min_samples_split':np.arange(2,61,10),'min_samples_leaf':np.arange(1,61,10)}\n",
    "best_max_depth, best_min_samples_split, best_min_samples_leaf = search_2(param_list_2)\n",
    "\n",
    "param_list_2 = {'max_depth':np.arange(best_max_depth-20,best_max_depth+20,5),\n",
    "                'min_samples_split':np.arange(best_min_samples_split-20,best_min_samples_split+20,5),\n",
    "                'min_samples_leaf':np.arange(1,31,5)}\n",
    "best_max_depth, best_min_samples_split, best_min_samples_leaf = search_2(param_list_2)\n",
    "\n",
    "param_list_2 = {'max_depth':np.arange(best_max_depth-10,best_max_depth+10,2),\n",
    "                'min_samples_split':np.arange(best_min_samples_split-9,best_min_samples_split+10,2),\n",
    "                'min_samples_leaf':np.arange(1,5)}\n",
    "best_max_depth, best_min_samples_split, best_min_samples_leaf = search_2(param_list_2)\n",
    "\n",
    "param_list_2 = {'max_depth':np.arange(best_max_depth-5,best_max_depth+5),\n",
    "                'min_samples_split':np.arange(best_min_samples_split-5,best_min_samples_split+5),\n",
    "                'min_samples_leaf':np.arange(1,3)}\n",
    "best_max_depth, best_min_samples_split, best_min_samples_leaf = search_2(param_list_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数调整，首先对‘n_estimators’，‘max_depth’，‘min_samples_split’，‘min_samples_leaf’进行最后一次小范围搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 13, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 135} 0.813966688456\n",
      "CPU times: user 4.01 s, sys: 306 ms, total: 4.31 s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def search_3(param_list):\n",
    "    gs = GridSearchCV(estimator=RandomForestClassifier(random_state=10),param_grid=param_list,scoring='roc_auc',cv=5,n_jobs=-1)\n",
    "    gs.fit(X_train,y_train)\n",
    "    print(gs.best_params_,gs.best_score_)\n",
    "    return gs.best_params_['n_estimators'], gs.best_params_['max_depth'], gs.best_params_['min_samples_split'], gs.best_params_['min_samples_leaf']\n",
    "param_list_3 = {'n_estimators':np.arange(best_n_estimators-3,best_n_estimators+3),\n",
    "                'max_depth':np.arange(best_max_depth-3,best_max_depth+3),\n",
    "                'min_samples_split':np.arange(best_min_samples_split-3,best_min_samples_split+3),\n",
    "                'min_samples_leaf':np.arange(1,3)}\n",
    "best_n_estimators, best_max_depth, best_min_samples_split, best_min_samples_leaf = search_3(param_list_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用各个最佳参数，训练第二个模型预测X_target，得分0.86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.859090909091\n",
      "CPU times: user 250 ms, sys: 4.8 ms, total: 254 ms\n",
      "Wall time: 252 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rfc_2 = RandomForestClassifier(n_estimators=best_n_estimators,max_depth=best_max_depth,\n",
    "                               min_samples_split=best_min_samples_split,min_samples_leaf=best_min_samples_leaf,\n",
    "                               oob_score=True, random_state=10)\n",
    "rfc_2.fit(X_train, y_train)\n",
    "print(rfc_2.oob_score_)\n",
    "result_2 = pd.DataFrame(rfc_2.predict(X_target),columns=['result'])\n",
    "result_2.to_csv('result_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
